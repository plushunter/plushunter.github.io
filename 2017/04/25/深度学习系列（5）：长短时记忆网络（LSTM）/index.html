<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<script data-ad-client="ca-pub-6293681360909288" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="深度学习,长短时记忆网络," />





  <link rel="alternate" href="/atom.xml" title="Free Will" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.ico?v=5.1.0" />






<meta name="description" content="一、长期依赖问题（Long-Term Dependencies）循环神经网络（RNN）在实际应用中很难处理长距离依赖的问题。 有的时候，我们仅仅需要知道先前的信息来完成预测任务。例如，我们有一个语言模型用来基于先前的词来预测下一个词，比如我们预测“the clouds are in the sky”最后的词的时候，我们不需要任何其他的上下文，很显然下一个词就是sky。在这种情况下，相关的信息与需要">
<meta name="keywords" content="深度学习,长短时记忆网络">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习系列（5）：长短时记忆网络（LSTM）">
<meta property="og:url" content="http://yoursite.com/2017/04/25/深度学习系列（5）：长短时记忆网络（LSTM）/index.html">
<meta property="og:site_name" content="Free Will">
<meta property="og:description" content="一、长期依赖问题（Long-Term Dependencies）循环神经网络（RNN）在实际应用中很难处理长距离依赖的问题。 有的时候，我们仅仅需要知道先前的信息来完成预测任务。例如，我们有一个语言模型用来基于先前的词来预测下一个词，比如我们预测“the clouds are in the sky”最后的词的时候，我们不需要任何其他的上下文，很显然下一个词就是sky。在这种情况下，相关的信息与需要">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d40314e0971536201.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d403158a61fb37281.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d403163b944289170.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d40316df0ca686667.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d40317c60de065977.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d4031862f34c83246.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d403190d3d1083774.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d4031a0de5bd99402.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d4031b9100ef81397.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d4031c8b796c98256.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d4031dd814d584167.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d403200e90bf75274.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d40320dbdad928416.jpg">
<meta property="og:updated_time" content="2019-07-30T12:03:30.147Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习系列（5）：长短时记忆网络（LSTM）">
<meta name="twitter:description" content="一、长期依赖问题（Long-Term Dependencies）循环神经网络（RNN）在实际应用中很难处理长距离依赖的问题。 有的时候，我们仅仅需要知道先前的信息来完成预测任务。例如，我们有一个语言模型用来基于先前的词来预测下一个词，比如我们预测“the clouds are in the sky”最后的词的时候，我们不需要任何其他的上下文，很显然下一个词就是sky。在这种情况下，相关的信息与需要">
<meta name="twitter:image" content="https://i.loli.net/2019/07/30/5d40314e0971536201.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"always","onmobile":true},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>









  <title> 深度学习系列（5）：长短时记忆网络（LSTM） | Free Will </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  



  <!-- hexo-inject:begin --><!-- hexo-inject:end --><script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?9a21041c6a1d47620a3a748589516274";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>









  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Free Will</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tech-stack">
          <a href="/tech-stack" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-balance-scale"></i> <br />
            
            技术栈
          </a>
        </li>
      
        
        <li class="menu-item menu-item-holzwege">
          <a href="/holzwege" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tripadvisor"></i> <br />
            
            林中路
          </a>
        </li>
      
        
        <li class="menu-item menu-item-on-earth">
          <a href="/on-earth" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-empire"></i> <br />
            
            人间事
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user-secret"></i> <br />
            
            关于我
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜一下
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input" placeholder="search my blog...">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  

</nav>


 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/25/深度学习系列（5）：长短时记忆网络（LSTM）/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="狗皮膏药">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/img/v.png">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Free Will">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Free Will" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                深度学习系列（5）：长短时记忆网络（LSTM）
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-25T23:14:45+08:00">
                2017-04-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-eye"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="一、长期依赖问题（Long-Term-Dependencies）"><a href="#一、长期依赖问题（Long-Term-Dependencies）" class="headerlink" title="一、长期依赖问题（Long-Term Dependencies）"></a>一、长期依赖问题（Long-Term Dependencies）</h2><p>循环神经网络（RNN）在实际应用中很难处理长距离依赖的问题。</p>
<p>有的时候，我们仅仅需要知道先前的信息来完成预测任务。例如，我们有一个语言模型用来基于先前的词来预测下一个词，比如我们预测“the clouds are in the sky”最后的词的时候，我们不需要任何其他的上下文，很显然下一个词就是sky。在这种情况下，相关的信息与需要预测的词位置之间的间隔很小，而RNN可以学会使用较近距离的信息。</p>
<a id="more"></a>
<p><img src="https://i.loli.net/2019/07/30/5d40314e0971536201.jpg" alt=""></p>
<p>但是到了一个更加复杂的场景，假设我们试着预测“I grew up in France……I speak fluent French”中最后的词，从这句话的信息来看，下一个词很有可能是一种语言的名字，但具体到是哪种语言，我们就需要在与之距离较远的“I grew up in France”中得到。这说明相关信息与当前预测位置之间的间隔就肯定变得相当的大。</p>
<p>不幸的是，在这个间隔不断增大时，RNN会丧失学习到连接如此远的信息的能力。<br><img src="https://i.loli.net/2019/07/30/5d403158a61fb37281.jpg" alt=""></p>
<p>当然，在理论上，RNN绝对可以处理这样的长期依赖问题。人们可以通过调参来解决，但是在实践中，RNN肯定不能够成功学习到这些知识。<a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" target="_blank" rel="noopener">Bengio, et al. (1994)</a>等人对该问题进行了深入的研究，它们发现一些使训练RNN变得非常困难的相当根本的原因。</p>
<p>既然找到了问题的原因，那我们就能解决它。从问题的定位到解决，科学家们大概花了7、8年的时间。终于有一天，Hochreiter和Schmidhuber两位科学家发明出长短时记忆网络，一举解决了这个问题。</p>
<h2 id="二、LSTM的核心思想"><a href="#二、LSTM的核心思想" class="headerlink" title="二、LSTM的核心思想"></a>二、LSTM的核心思想</h2><p>Long Short Term网络，一般就叫做LSTM，是一种特殊的RNN变体，它可以学习长期依赖信息。LSTM由Hochreiter和Schmidhuber在1997年提出，并在近期被Alex Graves进行了改良和推广。在很多问题上，LSTM都取得了相当巨大的成功，并得到了广泛的使用。<br>LSTM通过刻意的设计来避免长期依赖问题。记住长期的信息在实践中是LSTM的默认属性，而非需要付出很大的代价才能获得的能力！<br>所有的RNN都具有一种重复神经网络模块的链式的形式。在标准的RNN中，这个重复的模块只有一个非常简单的结构，例如一个tanh层。<br><img src="https://i.loli.net/2019/07/30/5d403163b944289170.jpg" alt=""><br>LSTM同样是这样的结构，但是其中重复的模块拥有一个不同的结构。不同于单一神经网络层，这里有四个以非常特殊的方式进行交互的小器件。<br><img src="https://i.loli.net/2019/07/30/5d40316df0ca686667.jpg" alt=""><br>图中每一条黑线传输着一整个向量，从一个节点的输出到其他节点的输入。粉色的圈代表pointwise的操作，比如向量的和，而黄色的矩阵就是学习到的神经网络层。</p>
<p>LSTM的关键在于细胞（Cell），水平线在细胞内贯穿运行。细胞类似于传送带。直接在整个链上运行，只有一些少量的线性交互。信息在水平线上很容易保持不变。<br><img src="https://i.loli.net/2019/07/30/5d40317c60de065977.jpg" alt=""></p>
<p>LSTM通过精心设计“门”结构来去除或者增加信息到Cell上。门是一种让信息选择式通过的方法（过滤器）。它们包含一个sigmoid神经网络层和一个pointwise乘法操作。<br><img src="https://i.loli.net/2019/07/30/5d4031862f34c83246.jpg" alt=""></p>
<p>Sigmoid层输出0到1之间的数值，描述每个部分有多少量可以通过。0代表“不许任何量通过”，1就指“允许任意量通过”</p>
<h2 id="三、LSTM的前向计算"><a href="#三、LSTM的前向计算" class="headerlink" title="三、LSTM的前向计算"></a>三、LSTM的前向计算</h2><p>LSTM用两个门来控制单元状态Cell的内容，一个是遗忘门（forget gate），它决定了上一时刻的单元状态$c_t-1$有多少保留到当前时刻$c_t$；另一个是输入门（input gate），他决定了当前时刻网络的输入$x_t$有多少保存到单元状态$c_t$。LSTM用输出门（output gate）来控制单元状态$c_t$有多少输出到LSTM的当前输出值$h_t$。</p>
<h3 id="3-1-遗忘门"><a href="#3-1-遗忘门" class="headerlink" title="3.1 遗忘门"></a>3.1 遗忘门</h3><p>我们先看一下遗忘门：</p>
<script type="math/tex; mode=display">f_t=\sigma(W_f·[h_{t-1,x_t}]+b_f)</script><p>上式中，$W_f$是遗忘门的权重矩阵，$[h_{t-1},x_t]$表示把两个向量连接成一个更长的向量，$b_f$是遗忘门的偏置项，$\sigma$是sigmoid函数。若输入的维度是$d_x$，隐藏层的维度是$d_h$，单元状态的维度是$d_c$（通常$d_c=d_h$），则遗忘门的权重矩阵$W_f$维度是$d_c×(d_h+d_x)$。事实上，权重矩阵$W_f$都是两个矩阵拼接而成的：一个是$W_{fh}$，它对应着输入项$h_{t-1}$，其维度为$d_c×d_h$；一个是$W_{fx}$，它对应着输入项$x_t$，其维度为$d_c×d_x$。$W_f$可以写为：</p>
<script type="math/tex; mode=display">
\left[W_f\right]\left[\begin{array}{c}
    h_{t-1}\\
    x_t\\
\end{array}\right]=\left[\begin{matrix}
    W_{fh}&        W_{fx}\\
\end{matrix}\right]\left[\begin{array}{c}
    h_{t-1}\\
    x_t\\
\end{array}\right]=W_{fh}·h_{t-1}+W_{fx}x_t</script><p>所以总结一下，遗忘门的作用为控制有多少上一时刻的memory cell中的信息可以累积到当前时刻的memory cell中。其数学公式可以写作：</p>
<script type="math/tex; mode=display">f_t = sigmoid(W_{fx}·x_t+W_{fh}·h_{t-1}+b_i)</script><p>其计算图示如下：<br><img src="https://i.loli.net/2019/07/30/5d403190d3d1083774.jpg" alt=""></p>
<h3 id="3-2-输入门"><a href="#3-2-输入门" class="headerlink" title="3.2 输入门"></a>3.2 输入门</h3><p>接下来看输入门：</p>
<script type="math/tex; mode=display">i_t=\sigma(W_i·[h_{t-1},x_t]+b_i)</script><p>上式中，$W_i$是输入们的权重矩阵，$b_i$是输入门的偏置项。下图表示了输入门的计算：<img src="https://i.loli.net/2019/07/30/5d4031a0de5bd99402.jpg" alt=""></p>
<p>接下来，我们计算用于描述当前输入的单元状态$\tilde{c}_t$，它是根据上一次的输出和本次输入来计算的：</p>
<script type="math/tex; mode=display">\tilde{c}_t=\tan\textrm{h}\left(W_c·\left[h_{t-1},x_t\right]+b_c\right)</script><p>下图是$\tilde{c}_t$的计算：<br><img src="https://i.loli.net/2019/07/30/5d4031b9100ef81397.jpg" alt=""><br>现在，我们计算当前时刻的单元状态$c_t$。它是由上一次的单元状态$c_{t-1}$按元素乘以遗忘门$f_t$，再用当前输入的单元状态$\tilde{c}_t$按元素乘以输入门$i_t$，再将两个积加和产生的：</p>
<script type="math/tex; mode=display">
c_t=f_t°c_{t-1}+i_t°\tilde{c}_t</script><p>下图是$c_t$的计算图示：<img src="https://i.loli.net/2019/07/30/5d4031c8b796c98256.jpg" alt=""><br>这样，我们就把LSTM关于当前的记忆$\tilde{c}_t$和长期的记忆$c_{t-1}$组合在一起，形成了新的单元状态$c_t$。由于遗忘门的控制，它可以保存很久很久之前的信息，由于输入门的控制，它又可以避免当前无关紧要的内容进入记忆。</p>
<h3 id="3-3-输出门"><a href="#3-3-输出门" class="headerlink" title="3.3 输出门"></a>3.3 输出门</h3><p>下面，我们要看看输入门，它控制了长期记忆对当前输出的影响：</p>
<script type="math/tex; mode=display">o_t=\sigma(W_o·[h_{t-1},x_t]+b_o)</script><p>下图表示输出门的计算：<br><img src="https://i.loli.net/2019/07/30/5d4031dd814d584167.jpg" alt=""><br>LSTM最终的输出，是由输出门和单元状态共同确定的：</p>
<script type="math/tex; mode=display">h_t=o_t°\tan\textrm{h}\left(c_t\right)</script><p>下图表示LSTM最终输出的计算：<img src="https://i.loli.net/2019/07/30/5d403200e90bf75274.jpg" alt=""></p>
<h2 id="四、LSTM的训练"><a href="#四、LSTM的训练" class="headerlink" title="四、LSTM的训练"></a>四、LSTM的训练</h2><p>LSTM的训练算法仍然是反向传播算法，它主要有下面三个步骤：</p>
<ul>
<li>1）前向计算每个神经元的输出值，对于LSTM来说，即$f_t、i_t、c_t、o_t、h_t$五个向量的值。</li>
<li>2）反向计算每个神经元的误差项$\delta$值。与循环神经网络一样，LSTM误差项的反向传播也是包括两个方向：一个是沿着时间的反向传播，即从当前t时刻开始，计算每个时刻的误差项；一个是将误差项向上一层传播。</li>
<li>3）根据相应的误差项，计算每个权重的梯度。</li>
</ul>
<p>首先，我们队推导中用到的一些公式、符号做一下必要的说明。</p>
<p>接下来的推导中，我们设定gate的激活函数为sigmoid函数，输出的激活函数为tanh函数。它们的导数分别为：</p>
<script type="math/tex; mode=display">
\sigma\left(z\right)=y=\frac{1}{1+e^{-z}}</script><script type="math/tex; mode=display">
\sigma '\left(z\right)=y\left(1-y\right)</script><script type="math/tex; mode=display">
\tan\textrm{h}\left(z\right)=y=\frac{e^z-e^{-z}}{e^z+e^{-z}}</script><script type="math/tex; mode=display">
\tan\textrm{h'}\left(z\right)=1-y^2</script><p>从上面可以看出，sigmoid和tanh函数的导数都是原函数的函数。这样，我们一旦计算原函数的值，就可以用它来计算出导数的值。</p>
<p>LSTM需要学习的参数共有8组，分别是：遗忘门的权重矩阵$W_f$和偏置项$b_f$、输入门的权重矩阵$W_i$和偏置项$b_i$、输出门的权重矩阵$W_o$和偏置项$b_o$，以及计算单元状态的权重矩阵$W_c$和偏置项$b_c$，因为权重矩阵的两部分在反向传播中使用不同的公式，因此在后续的推导中，权重矩阵$W_f、W_i、W_c、W_o$都会被写成分开的两个矩阵：$W_{fh}、W_{fx}、W_{ih}、W_{ix}、W_{oh}、W_{ox}、W_{ch}、W_{cx}$。</p>
<p>我们解释一下按元素乘$o$符号。当$o$作用于两个向量时，运算如下：</p>
<script type="math/tex; mode=display">
a°b=\left[\begin{array}{c}
    a_1\\
    a_2\\
    ···\\
    a_n\\
\end{array}\right]°\left[\begin{array}{c}
    b_1\\
    b_2\\
    ···\\
    b_n\\
\end{array}\right]=\left[\begin{array}{c}
    a_1b_1\\
    a_2b_2\\
    ···\\
    a_nb_n\\
\end{array}\right]</script><p>当$o$作用于一个向量和一个矩阵时，运算如下：</p>
<script type="math/tex; mode=display">
a°X=\left[\begin{array}{c}
    a_1\\
    a_2\\
    ···\\
    a_n\\
\end{array}\right]°\left[\begin{matrix}
    x_{11}&        x_{12}&        ···&        x_{1n}\\
    x_{21}&        x_{22}&        ···&        x_{2n}\\
    ···&        ···&        ···&        ···\\
    x_{n1}&        x_{n2}&        ···&        x_{nn}\\
\end{matrix}\right]=\left[\begin{matrix}
    a_1x_{11}&        a_1x_{12}&        ···&        a_{1n}x_{1n}\\
    a_2x_{21}&        a_2x_{22}&        ···&        a_2x_{2n}\\
    ···&        ···&        ···&        ···\\
    a_nx_{n1}&        a_nx_{n2}&        ···&        a_nx_{nn}\\
\end{matrix}\right]</script><p>当$o$作用于两个矩阵时，两个矩阵对应位置的元素相乘。按元素乘可以再某些情况下简化矩阵和向量的运算。例如，当一个对角矩阵右乘一个矩阵时，相当于用对角矩阵的对角线组成的向量按元素乘那个矩阵：$diag[a]·X=a °X$当一个行向量右乘一个对角矩阵时，相当于这个行向量按元素乘那个矩阵对角线组成的向量：</p>
<script type="math/tex; mode=display">a^T·diag[b]=a°b</script><p>上面这俩点，在后续推导中会多次用到。</p>
<p>在t时刻，LSTM的输出值为$h_t$。我们定义t时刻的误差项$\delta_t$为：</p>
<script type="math/tex; mode=display">\delta_t=\frac{\partial E}{\partial h_t}</script><p>注意，这里假设误差项是损失函数对输出值的导数，而不是对加权输入$net^l$的导数。因为LSTM有四个加权输入，分别对应$f_t、i_t、c_t、o_t$，我们希望往上一层传递一个误差项而不是四个。但我们仍然要定义出这四个加权输入，以及他们对应的误差项。</p>
<script type="math/tex; mode=display">net_{f,t}=W_f[h_{t-1},x_t]+b_f=W_{fh}h_{t-1}+W_{fx}x_t+b_f</script><script type="math/tex; mode=display">net_{i,t}=W_i[h_{t-1},x_t]+b_i=W_{ih}h_{t-1}+W_{ix}x_t+b_i</script><script type="math/tex; mode=display">net_{\tilde{c},t}=W_c\left[h_{t-1},x_t\right]+b_c=W_{ch}h_{t-1}+W_{cx}x_t+b_c</script><script type="math/tex; mode=display">net_{o,t}=W_o\left[h_{t-1},x_t\right]+b_o=W_{oh}h_{t-1}+W_{ox}x_t+b_o</script><script type="math/tex; mode=display">
\delta_{f,t}=\frac{\partial E}{\partial net_{f,t}}</script><script type="math/tex; mode=display">
\delta_{i,t}=\frac{\partial E}{\partial net_{i,t}}</script><script type="math/tex; mode=display">
\delta_{\tilde{c},t}=\frac{\partial E}{\partial net_{c,t}}</script><script type="math/tex; mode=display">
\delta_{o,t}=\frac{\partial E}{\partial net_{o,t}}</script><h3 id="4-1-误差项沿时间的反向传播"><a href="#4-1-误差项沿时间的反向传播" class="headerlink" title="4.1 误差项沿时间的反向传播"></a>4.1 误差项沿时间的反向传播</h3><p>沿时间反向传导误差项，就是要计算出$t-1$时刻的误差项$\delta_{t-1}$。</p>
<script type="math/tex; mode=display">
\delta_{t-1}^{T}=\frac{\partial E}{\partial h_{t-1}}</script><script type="math/tex; mode=display">
=\frac{\partial E}{\partial h_t}\frac{\partial h_t}{\partial h_{t-1}}</script><script type="math/tex; mode=display">
=\delta_{t}^{T}\frac{\partial h_t}{\partial h_{t-1}}</script><p>我们知道，$\frac{\partial h_t}{\partial h_{t-1}}$是一个jacobian矩阵。如果隐藏层$h$的维度是N的话，那么它就是一个$N×N$矩阵。为了求出它，我们列出$h_t$的计算公式：</p>
<script type="math/tex; mode=display">c_t=f_t°c_{t-1}+i_t°\tilde{c}_t</script><script type="math/tex; mode=display">h_t=o_t°\tan\textrm{h}\left(c_t\right)</script><p>显然，$o_t、f_t、i_t、\tilde{c}_t$都是$h_{t-1}$的函数，那么，利用全导数公式可得：</p>
<h3 id="4-2-将误差项传递到上一层"><a href="#4-2-将误差项传递到上一层" class="headerlink" title="4.2 将误差项传递到上一层"></a>4.2 将误差项传递到上一层</h3><h3 id="4-3-权重梯度的计算"><a href="#4-3-权重梯度的计算" class="headerlink" title="4.3 权重梯度的计算"></a>4.3 权重梯度的计算</h3><h2 id="五、LSTM的变体—GRU（Gated-Recurrent-Unit）"><a href="#五、LSTM的变体—GRU（Gated-Recurrent-Unit）" class="headerlink" title="五、LSTM的变体—GRU（Gated Recurrent Unit）"></a>五、LSTM的变体—GRU（Gated Recurrent Unit）</h2><p>前面我们讲了一种最为普通的LSTM，事实上LSTM存在很多变体，许多论文中的LSTM都或多或少的不太一样。只要遵守几个关键点，就可以根据需求设计需要的Gated RNNS。在众多的LSTM变体中，GRU也许是最成功的一种。它对LSTM做了很多简化，同时却保持着和LSTM相同的效果。因此，GRU最近变得越来越流行。</p>
<p>GRU对LSTM做了两个大改动：</p>
<ul>
<li>1）将输入门、遗忘门、输出门变为两个门：更新门（Update Gate）$z_t$和重置门（Reset Gate）$r_t$。</li>
<li>2）将单元状态与输出合并为一个状态：$h$</li>
</ul>
<p>GRU的前向计算公式为：</p>
<script type="math/tex; mode=display">z_t=\sigma(W_z·[h_{t-1},x_t])</script><script type="math/tex; mode=display">r_t=\sigma(W_r·[h_{t-1},x_t])</script><script type="math/tex; mode=display">
\tilde{h}_t=\tan\textrm{h}\left(W·\left[r_t°h_{t-1},x_t\right]\right)</script><script type="math/tex; mode=display">
h=\left(1-z_t\right)°h_{t-1}+z_t°\tilde{h}_t</script><p>下图是GRU的示意图：<img src="https://i.loli.net/2019/07/30/5d40320dbdad928416.jpg" alt=""><br>GRU的训练算法比LSTM相对也要简单一些</p>
<p>当然还有很多其他的变体，如<a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="noopener"> Gers &amp; Schmidhuber (2000) </a>提出的LSTM变体增加了“peephole connection”；另一种变体使用coupled 遗忘和输入门对遗忘和需要的信息一同做出决定。<a href="https://arxiv.org/pdf/1508.03790v2.pdf" target="_blank" rel="noopener">Yao, et al. (2015)</a> 提出的Depth Gated RNN。还有用一些完全不同的观点来解决长期依赖的问题，如<a href="https://arxiv.org/pdf/1402.3511v1.pdf" target="_blank" rel="noopener">Koutnik, et al. (2014) </a>提出的Clockwork RNN。</p>
<p>但<a href="https://arxiv.org/pdf/1503.04069.pdf" target="_blank" rel="noopener">Greff, et al. (2015)</a>给出了流行变体的比较，结论是它们基本上是一样的。<a href="http://proceedings.mlr.press/v37/jozefowicz15.pdf" target="_blank" rel="noopener">Jozefowicz, et al. (2015) </a>则在超过一万种RNN架构上进行了测试，发现一些架构在某些任务上也取得了比LSTM更好的结果。</p>

      
    </div>


    <div>
      
        

      
    </div>
<div>
  
    <div>
    
     <br> 
        <div style="text-align:center;color: #ccc;font-size:18px;"><br>-----------本文结束<i class="fa fa-paw"></i>
        感谢您的阅读-----------<br></div>
        <div><br>  
        <div align="center">
        欢迎关注我的个人微信公众号【机器联盟】
 </div> 
        <div align="center">

        <img src="https://i.loli.net/2019/11/29/6PoIQsAwkUNTd2b.jpg"/>
        </div> 
        </div>
    
</div>
  
</div>
    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>感谢打赏，您的支持将鼓励我继续创作！</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/img/wechat-reward-image.png" alt="狗皮膏药 WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/img/alipay-reward-image.png" alt="狗皮膏药 Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      

    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/深度学习/" rel="tag"># 深度学习</a>
          
            <a href="/tags/长短时记忆网络/" rel="tag"># 长短时记忆网络</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/04/23/深度学习系列（4）：循环神经网络（RNN）/" rel="next" title="深度学习系列（4）：循环神经网络（RNN）">
                <i class="fa fa-chevron-left"></i> 深度学习系列（4）：循环神经网络（RNN）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/04/26/深度学习系列（6）：递归神经网络/" rel="prev" title="深度学习系列（6）：递归神经网络">
                深度学习系列（6）：递归神经网络 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
      

    </footer>
  </article>



    <div class="post-spread">
      
        <!-- Go to www.addthis.com/dashboard to customize your tools -->
<div class="addthis_inline_share_toolbox">
  <script type = "text/javascript" src = "//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5bc405fb9346cd0b" async = "async" ></script>
</div>

      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/img/v.png"
                alt="狗皮膏药" />
            
              <p class="site-author-name" itemprop="name">狗皮膏药</p>
              <p class="site-description motion-element" itemprop="description">人类被赋予了一种工作，那就是精神的成长</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">204</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">306</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://plushunter.github.io/say-sth/" target="_blank" title="絮语">
                    
                      <i class="fa fa-fw fa-heartbeat"></i>絮语</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://plushunter.github.io/see-movies/" target="_blank" title="电影">
                    
                      <i class="fa fa-fw fa-film"></i>电影</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://plushunter.github.io/competitions" target="_blank" title="竞赛">
                    
                      <i class="fa fa-fw fa-database"></i>竞赛</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.zhihu.com/people/ren-da-ying-tong-hua-qi/activities" target="_blank" title="知乎">
                    
                      <i class="fa fa-fw fa-graduation-cap"></i>知乎</a>
                </span>
              
            
          </div>


          
          <div id="music163player">
           <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=986476&auto=1&height=66">
           </iframe>
          </div>


        


          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-anchor"></i>
                GREAT BLOG
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://blog.farmostwood.net" title="木遥" target="_blank">木遥</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://coolshell.cn" title="酷壳" target="_blank">酷壳</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://mindhacks.cn" title="刘未鹏" target="_blank">刘未鹏</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://freemind.pluskid.org" title="张驰原" target="_blank">张驰原</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.ruanyifeng.com/home.html" title="阮一峰" target="_blank">阮一峰</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.flickering.cn" title="火光摇曳" target="_blank">火光摇曳</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://macshuo.com" title="MacTalk" target="_blank">MacTalk</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.matrix67.com" title="Matrix67" target="_blank">Matrix67</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.statunion.cn" title="应统联盟" target="_blank">应统联盟</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://ml-union.github.io/about/" title="机器联盟" target="_blank">机器联盟</a>
                  </li>
                
              </ul>
            </div>
          


          

        </div>
        
      
  
          
            <div class="cc-license motion-element" itemprop="license">
              <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
                <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
              </a>
            </div>
          
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、长期依赖问题（Long-Term-Dependencies）"><span class="nav-text">一、长期依赖问题（Long-Term Dependencies）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、LSTM的核心思想"><span class="nav-text">二、LSTM的核心思想</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、LSTM的前向计算"><span class="nav-text">三、LSTM的前向计算</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-遗忘门"><span class="nav-text">3.1 遗忘门</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-输入门"><span class="nav-text">3.2 输入门</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-输出门"><span class="nav-text">3.3 输出门</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#四、LSTM的训练"><span class="nav-text">四、LSTM的训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-误差项沿时间的反向传播"><span class="nav-text">4.1 误差项沿时间的反向传播</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-将误差项传递到上一层"><span class="nav-text">4.2 将误差项传递到上一层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-权重梯度的计算"><span class="nav-text">4.3 权重梯度的计算</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#五、LSTM的变体—GRU（Gated-Recurrent-Unit）"><span class="nav-text">五、LSTM的变体—GRU（Gated Recurrent Unit）</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      


      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">狗皮膏药</span>
</div>



        

<div class="busuanzi-count">

  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    if (!String.prototype.endsWith) {
  String.prototype.endsWith = function(searchString, position) {
      var subjectString = this.toString();
      if (typeof position !== 'number' || !isFinite(position) || Math.floor(position) !== position || position > subjectString.length) {
        position = subjectString.length;
      }
      position -= searchString.length;
      var lastIndex = subjectString.indexOf(searchString, position);
      return lastIndex !== -1 && lastIndex === position;
  };
}
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


  


</body>
</html>
